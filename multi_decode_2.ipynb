{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'sub_2', 'index': 93, 'shape': array([  1, 257, 257,   3], dtype=int32), 'shape_signature': array([  1, 257, 257,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'MobilenetV1/heatmap_2/BiasAdd', 'index': 87, 'shape': array([ 1,  9,  9, 17], dtype=int32), 'shape_signature': array([ 1,  9,  9, 17], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'MobilenetV1/offset_2/BiasAdd', 'index': 90, 'shape': array([ 1,  9,  9, 34], dtype=int32), 'shape_signature': array([ 1,  9,  9, 34], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'MobilenetV1/displacement_fwd_2/BiasAdd', 'index': 84, 'shape': array([ 1,  9,  9, 32], dtype=int32), 'shape_signature': array([ 1,  9,  9, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'MobilenetV1/displacement_bwd_2/BiasAdd', 'index': 81, 'shape': array([ 1,  9,  9, 32], dtype=int32), 'shape_signature': array([ 1,  9,  9, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "path = \"./posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "interpreter = tf.lite.Interpreter(path)\n",
    "input_details = interpreter.get_input_details()\n",
    "print(str(input_details))\n",
    "output_details = interpreter.get_output_details()\n",
    "print(str(output_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'MobilenetV1/heatmap_2/BiasAdd', 'index': 87, 'shape': array([ 1,  9,  9, 17], dtype=int32), 'shape_signature': array([ 1,  9,  9, 17], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'MobilenetV1/offset_2/BiasAdd', 'index': 90, 'shape': array([ 1,  9,  9, 34], dtype=int32), 'shape_signature': array([ 1,  9,  9, 34], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'MobilenetV1/displacement_fwd_2/BiasAdd', 'index': 84, 'shape': array([ 1,  9,  9, 32], dtype=int32), 'shape_signature': array([ 1,  9,  9, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'MobilenetV1/displacement_bwd_2/BiasAdd', 'index': 81, 'shape': array([ 1,  9,  9, 32], dtype=int32), 'shape_signature': array([ 1,  9,  9, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "for v in output_details:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputstrides: 32.0 32.0\n"
     ]
    }
   ],
   "source": [
    "# check outputstrids:  resolution = ((InputImageSize - 1) / OutputStride) + 1\n",
    "\n",
    "output_stridex = (input_details[0]['shape'][1]-1)/(output_details[0]['shape'][1]-1)\n",
    "output_stridey = (input_details[0]['shape'][2]-1)/(output_details[0]['shape'][2]-1)\n",
    "print(\"outputstrides:\", output_stridex, output_stridey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stride = 32\n",
    "num_keypoints = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"/home/cp/Desktop/test1.png\"\n",
    "timg = Image.open(t1)\n",
    "timg2 = timg.resize((257,257))\n",
    "tim = np.array(timg2)\n",
    "tim2 = np.expand_dims(tim, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.11983823776245117\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "interpreter.set_tensor(input_details[0]['index'], tim2.astype(np.float32))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "t2 = time.time()\n",
    "print(\"time:\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = np.squeeze(interpreter.get_tensor(output_details[0]['index']))\n",
    "offsets = np.squeeze(interpreter.get_tensor(output_details[1]['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23, 17, 17), (23, 17, 34))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps.shape, offsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(heatmaps, offsets, output_stride=16.0):\n",
    "#     scores = np.sigmoid(heatmaps)\n",
    "    scores = heatmaps\n",
    "    num_keypoints = scores.shape[2]\n",
    "    heatmap_positions = []\n",
    "    offset_vectors = []\n",
    "    confidences = []\n",
    "    for ki in range(0, num_keypoints ):\n",
    "        x,y = np.unravel_index(np.argmax(scores[:,:,ki]), scores[:,:,ki].shape)\n",
    "        confidences.append(scores[x,y,ki])\n",
    "        offset_vector = (offsets[x,y,ki], offsets[x,y,num_keypoints+ki])\n",
    "        heatmap_positions.append((x,y))\n",
    "        offset_vectors.append(offset_vector)\n",
    "    image_positions = np.add(np.array(heatmap_positions) * output_stride, offset_vectors)\n",
    "    keypoints = [(i, pos, confidences[i]) for i, pos in enumerate(image_positions)]\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([325.4461565 , 250.78218555]), -6.1496406),\n",
       " (1, array([354.15077996, 222.89347756]), -6.304964),\n",
       " (2, array([321.87555075, 249.6857872 ]), -5.4582505),\n",
       " (3, array([305.31788659,  -2.75290179]), -6.501217),\n",
       " (4, array([325.01177835, 246.78412104]), -5.8539906),\n",
       " (5, array([359.13035011,  99.73285699]), -5.4797087),\n",
       " (6, array([360.20594025,  62.11213291]), -5.6351075),\n",
       " (7, array([ 37.88518763, 210.92842484]), -6.895049),\n",
       " (8, array([331.95654869, 242.40388417]), -6.560242),\n",
       " (9, array([307.25256658,  -7.66912794]), -6.995436),\n",
       " (10, array([294.67760611,  -7.45043898]), -6.7330246),\n",
       " (11, array([354.75411129,  33.2149421 ]), -6.204076),\n",
       " (12, array([358.17596674,  49.67506397]), -5.9366326),\n",
       " (13, array([324.2558732 , 260.58329153]), -7.461457),\n",
       " (14, array([353.31652951, 258.56145549]), -7.1741033),\n",
       " (15, array([352.59026635,  92.53342628]), -7.398567),\n",
       " (16, array([295.53600168,  -7.39525414]), -7.115737)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_keypoints(heatmaps, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 15 -6.1496406 (5.4461565, 10.782186)\n",
      "[325.4461565  250.78218555]\n",
      "22 14 -6.304964 (2.15078, -1.1065224)\n",
      "[354.15077996 222.89347756]\n",
      "20 15 -5.4582505 (1.8755507, 9.685787)\n",
      "[321.87555075 249.6857872 ]\n",
      "19 0 -6.501217 (1.3178866, -2.7529018)\n",
      "[305.31788659  -2.75290179]\n",
      "20 15 -5.8539906 (5.0117784, 6.784121)\n",
      "[325.01177835 246.78412104]\n",
      "22 6 -5.4797087 (7.13035, 3.732857)\n",
      "[359.13035011  99.73285699]\n",
      "22 4 -5.6351075 (8.20594, -1.8878671)\n",
      "[360.20594025  62.11213291]\n",
      "2 12 -6.895049 (5.8851876, 18.928425)\n",
      "[ 37.88518763 210.92842484]\n",
      "20 15 -6.560242 (11.956549, 2.4038842)\n",
      "[331.95654869 242.40388417]\n",
      "19 0 -6.995436 (3.2525666, -7.669128)\n",
      "[307.25256658  -7.66912794]\n",
      "18 0 -6.7330246 (6.677606, -7.450439)\n",
      "[294.67760611  -7.45043898]\n",
      "22 2 -6.204076 (2.7541113, 1.2149421)\n",
      "[354.75411129  33.2149421 ]\n",
      "22 3 -5.9366326 (6.1759667, 1.675064)\n",
      "[358.17596674  49.67506397]\n",
      "20 16 -7.461457 (4.255873, 4.5832915)\n",
      "[324.2558732  260.58329153]\n",
      "22 16 -7.1741033 (1.3165295, 2.5614555)\n",
      "[353.31652951 258.56145549]\n",
      "22 6 -7.398567 (0.59026635, -3.4665737)\n",
      "[352.59026635  92.53342628]\n",
      "18 0 -7.115737 (7.5360017, -7.395254)\n",
      "[295.53600168  -7.39525414]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_keypoints):\n",
    "    x,y = np.unravel_index(np.argmax(heatmaps[:,:,i]), heatmaps[:,:,i].shape) \n",
    "    conf = heatmaps[x,y,i]\n",
    "    offset_vector = (offsets[x,y,i], offsets[x,y,num_keypoints+i])\n",
    "    print(x,y,conf, offset_vector)\n",
    "\n",
    "    pos_i = np.add(np.array([x,y]) * output_stride, offset_vector)\n",
    "    print(pos_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resimg = visual(\"/home/cp/Desktop/test1.png\", kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(resdata):\n",
    "    if len(resdata.shape)==4:\n",
    "        resdata = resdata[0]\n",
    "    kps = []\n",
    "    for i in range(14):\n",
    "        tmpdata = resdata[:,:,i]\n",
    "        pos = np.unravel_index(np.argmax(tmpdata),tmpdata.shape)\n",
    "        kps.append(pos)\n",
    "    return kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(imgpath, kps):\n",
    "    timg = Image.open(imgpath)\n",
    "    w,h = timg.size\n",
    "    draw = ImageDraw.Draw(timg)\n",
    "    for row, col in kps:\n",
    "        row = int(row/17.0*w)\n",
    "        col = int(col/23.0*h)\n",
    "        draw.arc((col-2,row-2, col+2, row+2), 0,360, fill='red', width=1)\n",
    "    return timg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer this code:  https://github.com/rwightman/posenet-python/blob/master/posenet/decode_multi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog: https://towardsdatascience.com/optimizing-pose-estimation-on-the-coral-edge-tpu-d331c63cfed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another proach is to use js in android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
