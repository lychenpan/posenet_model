{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'image', 'index': 92, 'shape': array([  1, 337, 337,   3], dtype=int32), 'shape_signature': array([  1, 337, 337,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'heatmap_2', 'index': 91, 'shape': array([ 1, 22, 22, 17], dtype=int32), 'shape_signature': array([ 1, 22, 22, 17], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'offset_2', 'index': 93, 'shape': array([ 1, 22, 22, 34], dtype=int32), 'shape_signature': array([ 1, 22, 22, 34], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'displacement_fwd_2', 'index': 90, 'shape': array([ 1, 22, 22, 32], dtype=int32), 'shape_signature': array([ 1, 22, 22, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'displacement_bwd_2', 'index': 89, 'shape': array([ 1, 22, 22, 32], dtype=int32), 'shape_signature': array([ 1, 22, 22, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "path = \"./posenet_mv1_075_float_from_checkpoints.tflite\"\n",
    "interpreter = tf.lite.Interpreter(path)\n",
    "input_details = interpreter.get_input_details()\n",
    "print(str(input_details))\n",
    "output_details = interpreter.get_output_details()\n",
    "print(str(output_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'heatmap_2', 'index': 91, 'shape': array([ 1, 22, 22, 17], dtype=int32), 'shape_signature': array([ 1, 22, 22, 17], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'offset_2', 'index': 93, 'shape': array([ 1, 22, 22, 34], dtype=int32), 'shape_signature': array([ 1, 22, 22, 34], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'displacement_fwd_2', 'index': 90, 'shape': array([ 1, 22, 22, 32], dtype=int32), 'shape_signature': array([ 1, 22, 22, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'displacement_bwd_2', 'index': 89, 'shape': array([ 1, 22, 22, 32], dtype=int32), 'shape_signature': array([ 1, 22, 22, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "for v in output_details:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputstrides: 16.0 16.0\n"
     ]
    }
   ],
   "source": [
    "# check outputstrids:  resolution = ((InputImageSize - 1) / OutputStride) + 1\n",
    "output_stridex = (input_details[0]['shape'][1]-1)/(output_details[0]['shape'][1]-1)\n",
    "output_stridey = (input_details[0]['shape'][2]-1)/(output_details[0]['shape'][2]-1)\n",
    "print(\"outputstrides:\", output_stridex, output_stridey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stride = 16\n",
    "num_keypoints = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"./test.png\"\n",
    "timg = Image.open(t1)\n",
    "timg2 = timg.resize((337,337))\n",
    "tim = np.array(timg2)\n",
    "tim2 = np.expand_dims(tim, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.2821509838104248\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "interpreter.set_tensor(input_details[0]['index'], tim2.astype(np.float32))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "t2 = time.time()\n",
    "print(\"time:\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = np.squeeze(interpreter.get_tensor(output_details[0]['index']))\n",
    "offsets = np.squeeze(interpreter.get_tensor(output_details[1]['index']))\n",
    "dis1= np.squeeze(interpreter.get_tensor(output_details[2]['index']))\n",
    "dis2= np.squeeze(interpreter.get_tensor(output_details[3]['index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 22, 17), (22, 22, 34), (22, 22, 32), (22, 22, 32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps.shape, offsets.shape,dis1.shape, dis2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(imgpath, kps):\n",
    "    timg = Image.open(imgpath)\n",
    "    w,h = timg.size\n",
    "    draw = ImageDraw.Draw(timg)\n",
    "    for row, col in kps:\n",
    "        row = int(row/17.0*w)\n",
    "        col = int(col/23.0*h)\n",
    "        draw.arc((col-2,row-2, col+2, row+2), 0,360, fill='red', width=1)\n",
    "    return timg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer this code:  https://github.com/rwightman/posenet-python/blob/master/posenet/decode_multi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog: https://towardsdatascience.com/optimizing-pose-estimation-on-the-coral-edge-tpu-d331c63cfed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another proach is to use js in android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_nms_radius(poses, squared_nms_radius, point, keypoint_id):\n",
    "    for _, _, pose_coord in poses:\n",
    "        if np.sum((pose_coord[keypoint_id] - point) ** 2) <= squared_nms_radius:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def within_nms_radius_fast(pose_coords, squared_nms_radius, point):\n",
    "    if not pose_coords.shape[0]:\n",
    "        return False\n",
    "    return np.any(np.sum((pose_coords - point) ** 2, axis=1) <= squared_nms_radius)\n",
    "\n",
    "\n",
    "def get_instance_score(\n",
    "        existing_poses, squared_nms_radius,\n",
    "        keypoint_scores, keypoint_coords):\n",
    "    not_overlapped_scores = 0.\n",
    "    for keypoint_id in range(len(keypoint_scores)):\n",
    "        if not within_nms_radius(\n",
    "                existing_poses, squared_nms_radius,\n",
    "                keypoint_coords[keypoint_id], keypoint_id):\n",
    "            not_overlapped_scores += keypoint_scores[keypoint_id]\n",
    "    return not_overlapped_scores / len(keypoint_scores)\n",
    "\n",
    "\n",
    "def get_instance_score_fast(\n",
    "        exist_pose_coords,\n",
    "        squared_nms_radius,\n",
    "        keypoint_scores, keypoint_coords):\n",
    "\n",
    "    if exist_pose_coords.shape[0]:\n",
    "        s = np.sum((exist_pose_coords - keypoint_coords) ** 2, axis=2) > squared_nms_radius\n",
    "        not_overlapped_scores = np.sum(keypoint_scores[np.all(s, axis=0)])\n",
    "    else:\n",
    "        not_overlapped_scores = np.sum(keypoint_scores)\n",
    "    return not_overlapped_scores / len(keypoint_scores)\n",
    "\n",
    "\n",
    "def score_is_max_in_local_window(keypoint_id, score, hmy, hmx, local_max_radius, scores):\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "\n",
    "    y_start = max(hmy - local_max_radius, 0)\n",
    "    y_end = min(hmy + local_max_radius + 1, height)\n",
    "    x_start = max(hmx - local_max_radius, 0)\n",
    "    x_end = min(hmx + local_max_radius + 1, width)\n",
    "\n",
    "    for y in range(y_start, y_end):\n",
    "        for x in range(x_start, x_end):\n",
    "            if scores[y, x, keypoint_id] > score:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_part_with_score(score_threshold, local_max_radius, scores):\n",
    "    parts = []\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "    num_keypoints = scores.shape[2]\n",
    "\n",
    "    for hmy in range(height):\n",
    "        for hmx in range(width):\n",
    "            for keypoint_id in range(num_keypoints):\n",
    "                score = scores[hmy, hmx, keypoint_id]\n",
    "                if score < score_threshold:\n",
    "                    continue\n",
    "                if score_is_max_in_local_window(keypoint_id, score, hmy, hmx,\n",
    "                                                local_max_radius, scores):\n",
    "                    parts.append((\n",
    "                        score, keypoint_id, np.array((hmy, hmx))\n",
    "                    ))\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_part_with_score_fast(score_threshold, local_max_radius, scores):\n",
    "    parts = []\n",
    "    num_keypoints = scores.shape[2]\n",
    "    lmd = 2 * local_max_radius + 1\n",
    "\n",
    "    # NOTE it seems faster to iterate over the keypoints and perform maximum_filter\n",
    "    # on each subarray vs doing the op on the full score array with size=(lmd, lmd, 1)\n",
    "    for keypoint_id in range(num_keypoints):\n",
    "        kp_scores = scores[:, :, keypoint_id].copy()\n",
    "        kp_scores[kp_scores < score_threshold] = 0.\n",
    "        max_vals = ndi.maximum_filter(kp_scores, size=lmd, mode='constant')\n",
    "        max_loc = np.logical_and(kp_scores == max_vals, kp_scores > 0)\n",
    "        max_loc_idx = max_loc.nonzero()\n",
    "        for y, x in zip(*max_loc_idx):\n",
    "            parts.append((\n",
    "                scores[y, x, keypoint_id],\n",
    "                keypoint_id,\n",
    "                np.array((y, x))\n",
    "            ))\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf1, conf2, coords = decode_multiple_poses(heatmaps, offsets, dis1, dis2, output_stride, max_pose_detections=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_multiple_poses(\n",
    "        scores, offsets, displacements_fwd, displacements_bwd, output_stride,\n",
    "        max_pose_detections=10, score_threshold=0.5, nms_radius=20, min_pose_score=0.5):\n",
    "\n",
    "    pose_count = 0\n",
    "    pose_scores = np.zeros(max_pose_detections)\n",
    "    pose_keypoint_scores = np.zeros((max_pose_detections, NUM_KEYPOINTS))\n",
    "    pose_keypoint_coords = np.zeros((max_pose_detections, NUM_KEYPOINTS, 2))\n",
    "\n",
    "    squared_nms_radius = nms_radius ** 2\n",
    "\n",
    "    scored_parts = build_part_with_score_fast(score_threshold, LOCAL_MAXIMUM_RADIUS, scores)\n",
    "    scored_parts = sorted(scored_parts, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # change dimensions from (h, w, x) to (h, w, x//2, 2) to allow return of complete coord array\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "    offsets = offsets.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "    displacements_fwd = displacements_fwd.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "    displacements_bwd = displacements_bwd.reshape(height, width, 2, -1).swapaxes(2, 3)\n",
    "\n",
    "    for root_score, root_id, root_coord in scored_parts:\n",
    "        root_image_coords = root_coord * output_stride + offsets[\n",
    "            root_coord[0], root_coord[1], root_id]\n",
    "\n",
    "        if within_nms_radius_fast(\n",
    "                pose_keypoint_coords[:pose_count, root_id, :], squared_nms_radius, root_image_coords):\n",
    "            continue\n",
    "\n",
    "        keypoint_scores, keypoint_coords = decode_pose(\n",
    "            root_score, root_id, root_image_coords,\n",
    "            scores, offsets, output_stride,\n",
    "            displacements_fwd, displacements_bwd)\n",
    "\n",
    "        pose_score = get_instance_score_fast(\n",
    "            pose_keypoint_coords[:pose_count, :, :], squared_nms_radius, keypoint_scores, keypoint_coords)\n",
    "\n",
    "        # NOTE this isn't in the original implementation, but it appears that by initially ordering by\n",
    "        # part scores, and having a max # of detections, we can end up populating the returned poses with\n",
    "        # lower scored poses than if we discard 'bad' ones and continue (higher pose scores can still come later).\n",
    "        # Set min_pose_score to 0. to revert to original behaviour\n",
    "        if min_pose_score == 0. or pose_score >= min_pose_score:\n",
    "            pose_scores[pose_count] = pose_score\n",
    "            pose_keypoint_scores[pose_count, :] = keypoint_scores\n",
    "            pose_keypoint_coords[pose_count, :, :] = keypoint_coords\n",
    "            pose_count += 1\n",
    "\n",
    "        if pose_count >= max_pose_detections:\n",
    "            break\n",
    "\n",
    "    return pose_scores, pose_keypoint_scores, pose_keypoint_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_to_targ_keypoint(\n",
    "        edge_id, source_keypoint, target_keypoint_id, scores, offsets, output_stride, displacements\n",
    "):\n",
    "    height = scores.shape[0]\n",
    "    width = scores.shape[1]\n",
    "\n",
    "    source_keypoint_indices = np.clip(\n",
    "        np.round(source_keypoint / output_stride), a_min=0, a_max=[height - 1, width - 1]).astype(np.int32)\n",
    "\n",
    "    displaced_point = source_keypoint + displacements[\n",
    "        source_keypoint_indices[0], source_keypoint_indices[1], edge_id]\n",
    "\n",
    "    displaced_point_indices = np.clip(\n",
    "        np.round(displaced_point / output_stride), a_min=0, a_max=[height - 1, width - 1]).astype(np.int32)\n",
    "\n",
    "    score = scores[displaced_point_indices[0], displaced_point_indices[1], target_keypoint_id]\n",
    "\n",
    "    image_coord = displaced_point_indices * output_stride + offsets[\n",
    "        displaced_point_indices[0], displaced_point_indices[1], target_keypoint_id]\n",
    "\n",
    "    return score, image_coord\n",
    "\n",
    "\n",
    "def decode_pose(\n",
    "        root_score, root_id, root_image_coord,\n",
    "        scores,\n",
    "        offsets,\n",
    "        output_stride,\n",
    "        displacements_fwd,\n",
    "        displacements_bwd\n",
    "):\n",
    "    num_parts = scores.shape[2]\n",
    "    num_edges = len(PARENT_CHILD_TUPLES)\n",
    "\n",
    "    instance_keypoint_scores = np.zeros(num_parts)\n",
    "    instance_keypoint_coords = np.zeros((num_parts, 2))\n",
    "    instance_keypoint_scores[root_id] = root_score\n",
    "    instance_keypoint_coords[root_id] = root_image_coord\n",
    "\n",
    "    for edge in reversed(range(num_edges)):\n",
    "        target_keypoint_id, source_keypoint_id = PARENT_CHILD_TUPLES[edge]\n",
    "        if (instance_keypoint_scores[source_keypoint_id] > 0.0 and\n",
    "                instance_keypoint_scores[target_keypoint_id] == 0.0):\n",
    "            score, coords = traverse_to_targ_keypoint(\n",
    "                edge,\n",
    "                instance_keypoint_coords[source_keypoint_id],\n",
    "                target_keypoint_id,\n",
    "                scores, offsets, output_stride, displacements_bwd)\n",
    "            instance_keypoint_scores[target_keypoint_id] = score\n",
    "            instance_keypoint_coords[target_keypoint_id] = coords\n",
    "\n",
    "    for edge in range(num_edges):\n",
    "        source_keypoint_id, target_keypoint_id = PARENT_CHILD_TUPLES[edge]\n",
    "        if (instance_keypoint_scores[source_keypoint_id] > 0.0 and\n",
    "                instance_keypoint_scores[target_keypoint_id] == 0.0):\n",
    "            score, coords = traverse_to_targ_keypoint(\n",
    "                edge,\n",
    "                instance_keypoint_coords[source_keypoint_id],\n",
    "                target_keypoint_id,\n",
    "                scores, offsets, output_stride, displacements_fwd)\n",
    "            instance_keypoint_scores[target_keypoint_id] = score\n",
    "            instance_keypoint_coords[target_keypoint_id] = coords\n",
    "\n",
    "    return instance_keypoint_scores, instance_keypoint_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PART_NAMES = [\n",
    "    \"nose\", \"leftEye\", \"rightEye\", \"leftEar\", \"rightEar\", \"leftShoulder\",\n",
    "    \"rightShoulder\", \"leftElbow\", \"rightElbow\", \"leftWrist\", \"rightWrist\",\n",
    "    \"leftHip\", \"rightHip\", \"leftKnee\", \"rightKnee\", \"leftAnkle\", \"rightAnkle\"\n",
    "]\n",
    "\n",
    "NUM_KEYPOINTS = len(PART_NAMES)\n",
    "\n",
    "PART_IDS = {pn: pid for pid, pn in enumerate(PART_NAMES)}\n",
    "\n",
    "CONNECTED_PART_NAMES = [\n",
    "    (\"leftHip\", \"leftShoulder\"), (\"leftElbow\", \"leftShoulder\"),\n",
    "    (\"leftElbow\", \"leftWrist\"), (\"leftHip\", \"leftKnee\"),\n",
    "    (\"leftKnee\", \"leftAnkle\"), (\"rightHip\", \"rightShoulder\"),\n",
    "    (\"rightElbow\", \"rightShoulder\"), (\"rightElbow\", \"rightWrist\"),\n",
    "    (\"rightHip\", \"rightKnee\"), (\"rightKnee\", \"rightAnkle\"),\n",
    "    (\"leftShoulder\", \"rightShoulder\"), (\"leftHip\", \"rightHip\")\n",
    "]\n",
    "\n",
    "CONNECTED_PART_INDICES = [(PART_IDS[a], PART_IDS[b]) for a, b in CONNECTED_PART_NAMES]\n",
    "\n",
    "LOCAL_MAXIMUM_RADIUS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
